# Platform 2 Platform matching backend tool

## Feedback

## Silvio Lorusso

-[x] it would be good to have a call to action when selecting the source, e.g. "Select the source you want to fetch articles from"
-[x] it might be good to have the panels more recognizable/distinct in terms of Publisher, to immediately understand what one is looking at, e.g. instead of having the Publisher expressed textually, having the logo of it
-[x] the double scrolling (which is very nice btw) is bit sloppy on Firefox 71.0
-[x] it might be good to have some reference to the article (such as the title), in the Match tab. For example, "Match suggestion 1: On populism"
-[x] when a match is added and the users clicks on the Match tab all the info (Publisher, Title) are empty
-[x] it might be good to make more evident when new Match suggestions are added, such as a small animation of the new tabs
-[ ] it might be interesting to allow the user to compare the ratings added by other users

## Open Set (Irina)

-[ ] matches from Open! seem to be mainly from 2015

### 2

I can absolutely relate to that!: 

> One thing I noticed is that sometimes I read an article and it’s not a match for what I am reading but I know another article it’s a match for… I am then tempted to search in reverse until I find what I have in mind. or would it make sense to note that down and add them manually? Ideally the tool also should make it possible, right? It’s recommended for one thing but as an editor I think its perfect form something else.

Could not help myself to make notes about relations with other articles, but could not find the ‘ideal’ match in the proposed options. 

Just was curious if an option of suggesting a match by the author might be interesting /feasible?

To continue with the thoughts I had during the test this weekend, I would mention two more: 

-[ ] As soon as I approved several matches, there is a list of them appear on the left window new my article. But when i click on them, i cannot read the these articles neither their titles. Perhaps would be handy to revisit the choice if there are several of them. 

-[ ] Marked as a match several articles by mistake. Therefore was wondering if it’s possible to come back to the choices and correct the mistake? 

## Online Open! (Jorinde)

In general, I like the testing environment and how it works a lot. But I am a bit confused about the match fixing itself. This is mainly because I almost don’t find any matches. Only very few, and also about these I was not super convinced. Also, I come across the same non-Open! articles again and again. And sometimes I experience the same as the others, that I know that a specific Open! article that is not in the picture could have been a much better match with a proposed text. This all is maybe due to the different sizes of the three text archives we compare, with different tagging approaches, and…?

How do you see this?

## Amateur Cities (Ania)

### 1

Now I started paying attention and I also get a lot from open online 2015, but could it be that a lot got published that year and that it’s the most likely one to pop up? I am also getting from other years, so they are definitely there.
One thing I noticed is that sometimes I read an article and it’s not a match for what I am reading but I know another article it’s a match for… I am then tempted to search in reverse until I find what I have in mind. or would it make sense to note that down and add them manually? Ideally the tool also should make it possible, right? It’s recommended for one thing but as an editor I think its perfect form something else.

### 2

Thank you for all the effort that you have put into this. I also think it’s a pleasant environment to work with and it worked well for me. I must say that I did find matches and also got ideas about matches (what Jorinde also mentioned). I think this is not relevant to the readers, but it is relevant to the editorial process. If you get a recommendation that fits something else you know of, that you can actually make that match yourself. 

I sometimes had trouble with rating the match. For instance I never used ‘1’ and a match. I would tend to think that it’s not a match then. Also it might be helpful especially for external testers to make an explanation on roll over or in the users guide what does it mean that I rate a match with a 5, 3 or 1.

The issue of different sample sizes is something I noticed as well. I don’t think I got any of the Open Set articles recommended, so maybe that would also be an issue to address, the likelihood of a recommendation to take place in proportion to the sample.

I hope that can be of help.
